---
title: "Impact of dysfunctional ubiquitination in response to cancer immunotherapy"
subtitle: <center> Archive code </center>
author: "Eric Bautista Farrerons (s212514)"
date: '`r paste("First created on January 2024. Updated on ", format(Sys.Date(), "%d %B %Y"))`'
output:
  html_document:
    css: style.css
    code_folding: hide
    fig_caption: yes
    toc: yes
    toc_float:
      collapsed: true
      smooth_scroll: true
    toc_depth: 4
    number_sections: true
---

```{r, message=FALSE}
### Load required libraries
library(readxl)
library(tidyverse)
library(dplyr)
library(knitr)
library(DT)
library(httr)
library(jsonlite)
library(VariantAnnotation)

### Load functions
source(file = "../02_functions.R")

### Define paths
current_dir <- getwd()

# MAF-like file
maf_data <- "../../data/_raw/41467_2017_1460_MOESM6_ESM_somatic_mutations.xlsx"
maf_path <- file.path(current_dir, 
                      maf_data)

### Read data
maf_df <- read_excel(maf_path,
                        skip=1,
                        col_names=TRUE)
```

## See mutations per patient

```{r}
unique_tumor_counts <- maf_df %>%
count(tumor_name, 
      sort = TRUE)  # Count unique values and sort

# Display the result
datatable(unique_tumor_counts, 
          extensions = 'Buttons', 
          options = list(
            dom = 'Bfrtip',
            buttons = c('copy', 'excel', 'csv'),
            scrollX=TRUE,
            pageLength=10,
            columnDefs = list(list(
              targets = "_all",
              render = JS(
                "function(data, type, row, meta) {",
                "  return data === null ? 'NA' : data;",
                "}"
              )
            ))
          ),
          caption = "Mutation counts per patient"
        )
```

## Pre-processing

```{r, warning=FALSE}
# Filter rows where Entrez_Gene_Id is 0
missing_entrez_df <- maf_df %>%
  filter(Entrez_Gene_Id == 0)

# Filter rows where Hugo_Symbol is Unknown
missing_hugo_df <- maf_df %>%
  filter(Hugo_Symbol == 'Unknown')

n_rows_1 <- nrow(missing_entrez_df)
n_rows_2 <- nrow(missing_hugo_df)

print(paste("Number of samples missing an Entrez ID:", n_rows_1))
print(paste("Number of samples missing Hugo Symbol:", n_rows_2))
```

## Export info to use Ensembl VEP (web version)

```{r}
### Extract info in correct format for VEP input
api_input <- maf_df %>% 
  select(Chromosome,
         Start_position,
         End_position,
         ref_allele,
         alt_allele,
         Strand) %>% 
  mutate(Allele_ref_alt = paste(ref_allele, 
                                alt_allele, 
                                sep = "/")) %>% 
  mutate(API_info = paste(Chromosome,
                          Start_position,
                          End_position,
                          Allele_ref_alt,
                          Strand,
                          sep = " "))
```

## Misc

```{r}
###### Only 200 input POST API request

# Assuming api_input is your dataframe and API_info is the column with variant information
variant_info <- api_input[1200:1399,]$API_info

# Convert the vector of variants into JSON
json_data <- toJSON(list(variants = variant_info))

# API URL (ensure the URL is correct and includes the necessary protocol, such as https)
url <- "https://grch37.rest.ensembl.org/vep/homo_sapiens/region"

# Set headers for POST request
headers <- c("Content-Type" = "application/json", "Accept" = "application/json")

# Send the POST request
mock_response <- POST(url, body = json_data, add_headers(.headers=headers))

# Check if the request was successful
if (status_code(mock_response) == 200) {
  # Parse the JSON response
  mock_results <- content(mock_response, "parsed", simplifyVector = TRUE)

  # Convert results to a data frame or manipulate as needed
  mock_results_df <- as.data.frame(mock_results)
} else {
  print(paste("Error:", status_code(mock_response)))
}

mock_results_df
```

```{r}
# Function to split the dataframe into smaller chunks
split_data <- function(df, chunk_size) {
  split_indices <- ceiling(seq_len(nrow(df)) / chunk_size)
  split(df, split_indices)
}

# Split api_input into chunks of 200 rows
chunks <- split_data(api_input, 200)

# Initialize an empty list to store results from each chunk
all_results <- list()

# API URL (use GRCh37)
url <- "https://grch37.rest.ensembl.org/vep/homo_sapiens/region"

# Set headers for POST request
headers <- c("Content-Type" = "application/json", "Accept" = "application/json")

# Function to process each chunk
process_chunk <- function(chunk) {
  
  # Convert the list of variants into JSON
  json_data <- toJSON(list(variants = chunk$API_info))
  
  # Send the POST request
  response <- POST(url, body = json_data, add_headers(.headers=headers))
  
  # Check if the request was successful
  if (status_code(response) == 200) {
    
    # Parse the JSON response
    content(response, "parsed", simplifyVector = TRUE)
  
    } else {
    warning(paste("Error on chunk:", status_code(response)))
    NULL
  }
}

# Iterate over each chunk, process it, and store the results
for (i in seq_along(chunks)) {
  cat("Processing chunk", i, "out of", length(chunks), "\n")
  results <- process_chunk(chunks[[i]])
  if (!is.null(results)) {
    all_results[[i]] <- results
  }
}

# Combine all results into a single data frame
results_df <- bind_rows(all_results)
```

```{r}
# Check if 'transcript_consequences' column exists and unnest it
if ("transcript_consequences" %in% colnames(results_df)) {
  results_df <- results_df %>%
    unnest(transcript_consequences,
           names_sep = "_")
}

# Check if 'intergenic_consequences' column exists and unnest it
if ("intergenic_consequences" %in% colnames(results_df)) {
  results_df <- results_df %>%
    unnest(intergenic_consequences,
           names_sep = "_")
}
```

```{r}
# Initialize an empty list to store the resulting data frames
result_dfs <- list()

# Iterate over each column in results_df
for (col_name in colnames(results_df)) {
  # Check if the column contains list-type objects
  if (any(sapply(results_df[[col_name]], is.list))) {
    # Unnest the column and store the resulting data frame in the list
    results_df <- results_df %>%
      unnest(col_name, 
             names_sep = "_")
  }
}
```

```{r}
datatable(results_df, 
          extensions = 'Buttons', 
          options = list(
            dom = 'Bfrtip',
            buttons = c('copy', 'excel', 'csv'),
            scrollX=TRUE,
            pageLength=10,
            columnDefs = list(list(
              targets = "_all",
              render = JS(
                "function(data, type, row, meta) {",
                "  return data === null ? 'NA' : data;",
                "}"
              )
            ))
          ),
          caption = "VEP result"
        )
```

```{r}
conseq_df <- as.data.frame(results_df[1]$transcript_consequences)
datatable(conseq_df, 
          extensions = 'Buttons', 
          options = list(
            dom = 'Bfrtip',
            buttons = c('copy', 'excel', 'csv'),
            scrollX=TRUE,
            pageLength=10,
            columnDefs = list(list(
              targets = "_all",
              render = JS(
                "function(data, type, row, meta) {",
                "  return data === null ? 'NA' : data;",
                "}"
              )
            ))
          ),
          caption = "Transcript consequences"
        )
```

## Get the Hugo Symbols & Ensembl Gene IDs from Entrez IDs

```{r}
# Connect to the Ensembl BioMart database
ensembl = biomaRt::useMart(biomart="ENSEMBL_MART_ENSEMBL", 
                  host="https://grch37.ensembl.org", 
                  path="/biomart/martservice",
                  dataset="hsapiens_gene_ensembl")

# Extracting non-NA and non-zero values and ensuring they are unique
entrez_ids <- unique(na.omit(maf_df$Entrez_Gene_Id[maf_df$Entrez_Gene_Id != 0]))

# Ensure that entrez_ids is a character vector
entrez_ids <- as.character(entrez_ids)

# Retrieve Hugo symbols & Ensembl gene ids
reannotated_df <- biomaRt::getBM(attributes = c("entrezgene_id", 
                                                "hgnc_symbol", 
                                                "ensembl_gene_id"),
                   filters = "entrezgene_id",
                   values = entrez_ids,
                   mart = ensembl)

# Rename columns so that they match maf_df
# reannotated_df <- reannotated_df %>%
#   dplyr::rename(
#     Entrez_Gene_Id = entrezgene_id,
#     Ensembl_Gene_Id = ensembl_gene_id
#   )

# Left join reannotated_df with maf_df
maf_df_updated <- maf_df %>%
  left_join(reannotated_df, by = c("Entrez_Gene_Id" = "entrezgene_id"))

# View the updated dataframe
DT::datatable(maf_df_updated, 
          extensions = c('Buttons'),
          options = list(
            dom = 'Bfrtip',
            buttons = c('copy', 'excel', 'csv'),
            scrollX=TRUE,
            pageLength=10,
            columnDefs = list(list(
              targets = "_all",
              render = JS(
                "function(data, type, row, meta) {",
                "  return data === null ? 'NA' : data;",
                "}"
              )
            ))
          ),
          caption = "MAF_df reannotated"
        )
```

```{r}
# Count the number of unique values in the ensembl_gene_id column
num_unique_values <- reannotated_df %>% 
  summarise(unique_count = n_distinct(entrezgene_id)) %>% 
  pull(unique_count)

# Print the number of unique values
print(paste("Number of unique Entrez Gene IDs in reannotated_df:", num_unique_values))

# Search for a particular Entrez_Gene_Id
reannotated_df %>% 
  filter(entrezgene_id == "100526835")
```

## DEBUG: explore unique values in columns

```{r}
vep_df_clean %>% 
  dplyr::count(MPC) %>%  
  arrange(desc(n))
```

```{r}
maf_df %>%
  group_by(sample_id, Entrez_Gene_Id, Codon_Change)
```

```{r}
maf_df_annotated %>%
  group_by(sample_id, Codon_Change, Ensembl_gene_id)
```

```{r}
maf_df_rowid <- maf_df %>%
  dplyr::mutate(ori_row_id = row_number(),
                temp_row_id = row_number())

# Assuming 'Exclude_Column' is the column you want to keep but exclude from the distinct check
# First, save the excluded column temporarily
temp_excluded_column <- maf_df_rowid %>%
  dplyr::select(row_id)

# Then, perform distinct operation without the excluded column
maf_df_distinct <- maf_df_rowid %>%
  dplyr::select(-row_id) %>%
  dplyr::distinct()

# Now, bind the temporarily saved column back row-wise (assuming the order hasn't been changed)
maf_df_distinct <- bind_cols(maf_df_distinct, temp_excluded_column)
```

```{r}
unique_maf_df <- maf_df %>%
  dplyr::distinct()

removed_rows <- dplyr::anti_join(maf_df,
                                unique_maf_df)

print(nrow(removed_rows))
```

```{r}
unique_maf_df_annotated <- maf_df_annotated %>%
  dplyr::distinct()

removed_rows <- dplyr::anti_join(maf_df_annotated,
                                unique_maf_df_annotated)

print(nrow(removed_rows))
```

```{r}
maf_df_annotated_wo_ensembl <- maf_df_annotated %>%
  dplyr::select(-Ensembl_gene_id)

# Identify unique rows based on specified columns
unique_rows <- maf_df_annotated_wo_ensembl %>%
  dplyr::distinct()

# Find rows in the original dataframe not present in the unique set (i.e., removed rows)
removed_rows <- dplyr::anti_join(maf_df_annotated_wo_ensembl,
                                         unique_rows)
print(nrow(removed_rows))
```

```{r}
list_of_drugs <- c("Vemurafenib (BRAFi)", "Dacarbazine", "Ipilimumab", "Binimetinib (MEKi) - after", "Nivolumab - after", "Pembroluzimab - after", "Selinexor - after", "Temodal", "IL-2")
```

```{r}
# Statistical test: Wilcoxon rank-sum test (also known as Mann-Whitney U test)
# It does not work well, probably because I just compare 2 values (R vs NR) for each pathway. I should try giving the distribution.
geneset_group <- names(gene_sets_list)[i:min(i+9, length(gene_sets_list))]

prepared_data_df <- fora_results_combinedGS_lof_df %>%
  dplyr::filter(pathway %in% geneset_group) %>%
  dplyr::mutate(Gene_ratio = overlap / size, Count = overlap) %>%
  dplyr::ungroup()

# Merge response info
combined_data <- prepared_data_df %>%
  dplyr::left_join(response_df, by = "sample_id")

# Calculate p-values for each pathway and store results, handling cases with insufficient data
p_values <- combined_data %>%
  dplyr::group_by(pathway) %>%
  dplyr::summarize(p_value = ifelse(n_distinct(patient_response) > 1,
                             wilcox.test(Count ~ patient_response, data = ., exact = FALSE)$p.value,
                             NA_real_)) %>%
  dplyr::ungroup()

# Merge p-values back with combined_data for annotation
combined_data <- dplyr::left_join(combined_data, p_values, by = "pathway")

combined_data
```

# Legacy ubiquitin GO terms DB

This is the code I used to find the first iteration of parent terms to build the DB.

## Build a DB of GO terms for ubiquitin-related Bio Processes (based on gene list)

#### Define which parent terms I want to use.
#### Get offspring for all parent terms, and filter for those parents that I selected.
#### Iterate through the ubiquitin terms from my gene list and annotate the parent terms.
#### Check the ones that have +1 GO parent term and reduce to 1.
#### Get Ensembl IDs related to those GO terms. 

```{r, message=FALSE, warning=FALSE}
# Query the databse
go_ubgenes_result <- queryMany(ub_ensembl_ids,
                 scopes='ensembl.gene', 
                 fields=c('ensembl.gene', 'name', 'summary', 'go', 'pfam'), 
                 species='human', 
                 return.as='DataFrame')

# Filter result for BP
go_ubgenes_bp_res <- go_ubgenes_result$go.BP # Filter for BP only
names(go_ubgenes_bp_res) <- ub_ensembl_ids # Set names

# Convert to data.frame each element of the list
go_ubgenes_bp_list <- lapply(go_ubgenes_bp_res, 
                             function(df) 
                               if (is.null(df)) data.frame(id = character(),
                                                           gocategory = character(), 
                                                           term = character()) 
                               else df %>% 
                                as.data.frame())
# Wrangle the data.frame
go_ubgenes_bp_list <- lapply(go_ubgenes_bp_list,
                             function(x) 
                               x %>% 
                                dplyr::rename(go_id = id) %>% 
                                dplyr::select(go_id,
                                              gocategory,
                                              term))
# Convert list of df to single data.frame
raw_ub_glist_go_bp_df <- bind_rows(go_ubgenes_bp_list, .id = "ensembl_id") %>%
  mutate(ensembl_id = stringr::str_replace(ensembl_id, "\\..*$", ""),
         ensembl_id = factor(ensembl_id, levels = ub_ensembl_ids))

# Set rownames to NULL
rownames(raw_ub_glist_go_bp_df) <- NULL

# Filter for unique ubiquitin GO terms
ub_glist_go_bp_df <- raw_ub_glist_go_bp_df %>% 
  dplyr::filter(str_detect(term, "ubiquitin")) %>%
  dplyr::distinct() %>% 
  dplyr::arrange(go_id)

# Get selected GO terms as parents and their offspring
ub_go_parent_terms <- c("GO:0016567", "GO:0016579", "GO:0006511", "GO:0010499", "GO:0010992", "GO:0051438", "GO:0070086", "GO:0120323", "GO:0031397", "GO:0031398", "GO:2000059", "GO:2000060")
all_offspring <- as.list(GOBPOFFSPRING) # Get the offspring terms
go_parent_list <- map(ub_go_parent_terms, function(x) {
  offspring <- all_offspring[[x]]
  # If offspring has elements, return it (with parent itself)
  if (length(offspring) > 1) {
    return(c(x, offspring))
  # If the offspring is not NA, return it (with parent itself)
  } else if (!is.na(offspring)) {
    return(c(x, offspring))
  # If the offspring is NA, return the GO term itself wrapped in a list
  } else {
    return(x)
  }
})
names(go_parent_list) <- ub_go_parent_terms

# Annotate the parents to ub_glist_go_bp_df
# Function to find parent GO terms for a given child GO term
find_parent_GO <- function(child_term, parent_list) {
  parents <- names(parent_list)[sapply(parent_list, function(children) child_term %in% children)]
  return(parents)
}

# Create the new 'go_parent' column
ub_glist_go_bp_df <- ub_glist_go_bp_df %>%
  dplyr::rowwise() %>%
  dplyr::mutate(go_parent = list(find_parent_GO(go_id, go_parent_list))) %>%
  dplyr::ungroup()

# Create a lookup table from go_id to term
lookup_table <- ub_glist_go_bp_df %>% 
  dplyr::select(go_id, term) %>% 
  dplyr::distinct()

# Check the ones that have +1 GO parent term and reduce to 1
go_terms_to_keep <- c("GO:0031397", "GO:0031398", "GO:2000059", "GO:2000060")

final_ub_glist_go_bp_df <- ub_glist_go_bp_df %>%
  mutate(go_parent = map_chr(go_parent, ~ {
    # Filter go_parent to keep only the terms in go_terms_to_keep
    kept_terms <- intersect(., go_terms_to_keep)
    
    # Sort and compare for specific condition
    if (identical(sort(.), sort(c("GO:0016579", "GO:0006511")))) {
      # If this specific match, return "GO:0016579"
      "GO:0016579"
    } else if (length(kept_terms) > 0 && length(.) > 1) {
      # If there are kept terms and the original list length is greater than 1, return them as a character vector
      paste(kept_terms, collapse = ", ")
    } else {
      # If the original list length is not greater than 1, return the original term(s) as a character string
      paste(., collapse = ", ")
    }
  }, .else = NA_character_)) # Provide a fallback for empty or NULL inputs

# Left join to incorporate parent GO terms
final_ub_glist_go_bp_df <- final_ub_glist_go_bp_df %>% 
  dplyr::left_join(lookup_table, by = c("go_parent" = "go_id")) %>% 
  dplyr::rename(go_term = term.x,
                go_parent_term = term.y)

# Count number of genes from samples in each ubiquitin go parent term
final_parent_term_count <- final_ub_glist_go_bp_df %>% 
  dplyr::group_by(go_parent_term) %>% 
  dplyr::count() %>% 
  dplyr::arrange(desc(n))

# Display
datatable(final_parent_term_count, 
          extensions = c('Buttons', 
                         'FixedColumns'), 
          options = list(
            dom = 'Bfrtip',
            buttons = c('copy', 'excel', 'csv'),
            scrollX=TRUE,
            pageLength=10,
            fixedColumns = list(leftColumns = 3), # Freeze the first 3 columns
            columnDefs = list(list(
              targets = "_all",
              render = JS(
                "function(data, type, row, meta) {",
                "  return data === null ? 'NA' : data;",
                "}"
              )
            ))
          ),
          caption = "Count of genes included in each ubiquitin go parent term."
        )

# ub_glist_go_bp_df %>% 
#   dplyr::select(ensembl_id) %>% 
#   dplyr::distinct()
# # Lost some genes in the way.

# Get all ensembl gene ids for the parent go terms using biomaRt
# Connect to the Ensembl BioMart database
ensembl = biomaRt::useMart(biomart="ENSEMBL_MART_ENSEMBL", 
                  host="https://grch37.ensembl.org", 
                  path="/biomart/martservice",
                  dataset="hsapiens_gene_ensembl")

# Retrieve Hugo symbols & Ensembl gene ids
go2ensembl_result <- biomaRt::getBM(attributes = c("go_id", 
                                                "ensembl_gene_id"),
                   filters = "go",
                   values = ub_go_parent_terms,
                   mart = ensembl)

###############################################################################

# ### Alternative: use BiomaRt with grch37
# # Get all GO terms for the ub genes using biomaRt
# # Connect to the GO BioMart database
# ensembl = biomaRt::useMart(biomart="ENSEMBL_MART_ENSEMBL", 
#                   host="https://grch37.ensembl.org", 
#                   path="/biomart/martservice",
#                   dataset="hsapiens_gene_ensembl")
# 
# # Retrieve GO & Ensembl gene ids
# ensembl2go_biomart_res <- biomaRt::getBM(attributes = c("namespace_1003",
#                                                         "name_1006",
#                                                         "go_id", 
#                                                         "ensembl_gene_id"),
#                    filters = "ensembl_gene_id",
#                    values = ub_ensembl_ids,
#                    mart = ensembl)
# 
# # Filter for biological_process
# ensembl2go_bp_res <- ensembl2go_biomart_res %>% 
#   dplyr::rename(go_category = namespace_1003,
#                 go_term = name_1006,
#                 ensembl_id = ensembl_gene_id) %>% 
#   dplyr::filter(go_category == "biological_process") %>% 
#   dplyr::distinct()
# 
# # ensembl2go_bp_res %>% 
# #   dplyr::select(ensembl_gene_id) %>% 
# #   dplyr::distinct()
# 
# # Here I lose 120 genes because GO annotation failed. Collect them for exploration.
# lost_genes3 <- setdiff(ub_ensembl_ids, ensembl2go_bp_res$ensembl_id)
# 
# # Join the mapping information back to the original data.frame
# final_df2 <- ensembl2go_bp_res %>%
#   left_join(go_mapping_df, by = "go_id")
# 
# # Handle cases where a child belongs to multiple parents
# final_df2 <- final_df2 %>%
#   group_by(ensembl_id, go_category, go_id, go_term) %>%
#   summarise(go_parent_id = paste(unique(go_parent_id), collapse = ", "),
#             category = paste(unique(category), collapse = ", "),
#             .groups = 'drop')
# 
# # Arrange columns in the desired order
# final_df2 <- final_df2 %>%
#   dplyr::select(ensembl_id, go_category, category, go_parent_id, go_term, go_id)
# 
# # Adding go_parent_term
# final_df2 <- final_df2 %>%
#   left_join(go_parent_term_mapping, by = "go_parent_id")
# 
# # Converting NAs and ordering columns
# annot_ub_glist_df2 <- final_df2 %>% 
#   mutate(across(everything(), ~na_if(.x, "NA"))) %>% 
#   dplyr::select(ensembl_id, 
#                 go_category, 
#                 category, 
#                 go_parent_id, 
#                 go_parent_term, 
#                 go_id, 
#                 go_term)
# 
# # Identify genes that don't have a parent
# ensembl_ids_all_na_category2 <- annot_ub_glist_df2 %>%
#   dplyr::group_by(ensembl_id) %>%
#   dplyr::summarize(all_na_in_category = all(is.na(category)), .groups = 'drop') %>%
#   dplyr::filter(all_na_in_category) %>%
#   dplyr::pull(ensembl_id)
# 
# final_df_filtered_all_na2 <- annot_ub_glist_df2 %>%
#   filter(ensembl_id %in% ensembl_ids_all_na_category2)
# 
# # Here I lose 154 genes because no parent was found. Collect them for exploration.
# lost_genes4 <- final_df_filtered_all_na2 %>% 
#   dplyr::distinct(ensembl_id) %>% 
#   dplyr::pull(ensembl_id)
# 
# ensembl_ids_with_non_na_category2 <- annot_ub_glist_df2 %>%
#   dplyr::group_by(ensembl_id) %>%
#   dplyr::summarize(any_non_na_in_category = any(!is.na(category)), .groups = 'drop') %>%
#   dplyr::filter(any_non_na_in_category) %>%
#   dplyr::pull(ensembl_id)
# 
# final_df_filtered_non_na2 <- annot_ub_glist_df2 %>%
#   filter(ensembl_id %in% ensembl_ids_with_non_na_category2)

# 400/674 genes remaining. 274 genes lost in total. Here I used GRCh37

###############################################################################

```

```{r}
# PFAM code

# DEPRECATED: TSV
# pfam_analysis_path1 <- file.path(data_path, "../pfam_output_01.tsv")
# pfam_analysis_path2 <- file.path(data_path, "../pfam_output_02.tsv")
# pfam_analysis_path3 <- file.path(data_path, "../pfam_output_03.tsv")
# pfam_analysis_path4 <- file.path(data_path, "../pfam_output_04.tsv")
# pfam_df1 <- read.csv(pfam_analysis_path1, sep="\t", header = FALSE)
# pfam_df2 <- read.csv(pfam_analysis_path2, sep="\t", header = FALSE)
# pfam_df3 <- read.csv(pfam_analysis_path3, sep="\t", header = FALSE)
# pfam_df4 <- read.csv(pfam_analysis_path4, sep="\t", header = FALSE)
# 
# header <- c("Protein_accession", "Sequence_MD5_digest", "Sequence_length", "Analysis", "Signature_accession", "Signature_description", "Start_location", "Stop_location", "Score", "Status", "Date", "InterPro_accession", "InterPro_description", "GO_annotations", "Pathways_annotations")
# 
# pfam_df <- bind_rows(pfam_df1, pfam_df2, pfam_df3, pfam_df4)
# colnames(pfam_df) <- header
# 
# # Convert the Score column to numeric
# pfam_df$Score <- as.numeric(pfam_df$Score)
# 
# # Filter to retain the row with the lowest Score for each unique Protein_accession
# pfam_1_df <- pfam_df %>%
#   dplyr::group_by(Protein_accession) %>%
#   dplyr::slice_min(order_by = Score, with_ties = FALSE) %>%
#   dplyr::ungroup() %>%
#   dplyr::rename(p_ensembl_id = Protein_accession,
#                 )
#   dplyr::select()

# DEPRECATED: XML

# # Function to extract PFAM info
# extract_family_inf <- function(file_path) {
#   # Parse the XML file
#   xml_data <- xmlParse(file_path)
#   
#   # Extract protein entries and then further navigate to the 'FAMILY' type entries
#   proteins <- getNodeSet(xml_data, "/protein")
#   
#   # Prepare a list to collect all relevant data
#   all_entries <- list()
#   
#   # Loop over each protein to extract FAMILY entries
#   for (protein in proteins) {
#     # Extract only FAMILY type entries within each protein
#     family_entries <- getNodeSet(protein, ".//entry[@type='FAMILY']")
#     
#     # Extract details from each FAMILY entry
#     entries_data <- lapply(family_entries, function(entry) {
#       data.frame(
#         Protein_accession = xmlValue(getNodeSet(protein, "./xref/@name")[1]),
#         Accession = xmlGetAttr(entry, "ac"),
#         Description = xmlGetAttr(entry, "desc"),
#         Name = xmlGetAttr(entry, "name"),
#         Type = xmlGetAttr(entry, "type"),
#         stringsAsFactors = FALSE  # Avoid factors to simplify data handling
#       )
#     })
#     
#     # Combine the data from this protein into the main list
#     all_entries <- append(all_entries, entries_data)
#   }
#   
#   # Combine all collected data into a single data frame
#   do.call(rbind, all_entries)
# }
# 
# # List of file paths
# file_paths <- c(
#   file.path(data_path, "../mock_prot.xml"),
#   file.path(data_path, "../pfam_output_01.xml"),
#   file.path(data_path, "../pfam_output_02.xml"),
#   file.path(data_path, "../pfam_output_03.xml"),
#   file.path(data_path, "../pfam_output_04.xml")
# )
# 
# # Initialize an empty list to store data frames from all files
# all_data <- list()
# 
# # Process each file
# for (file_path in file_paths) {
#   all_data[[file_path]] <- extract_family_inf(file_path)
# }
# 
# # Combine all data frames into one
# final_df <- do.call(rbind, all_data)
# 
# # Optional: Convert the list of data frames into a single data frame if not already done
# final_df <- dplyr::bind_rows(all_data)

# Function to extract FAMILY (broken)
# Function to extract PFAM info
extract_family_info <- function(file_path) {
  # Load and parse the JSON data from file
  json_data <- fromJSON(file_path, flatten = TRUE)
  
  # Initialize an empty data frame for collecting FAMILY type entries
  family_entries_df <- data.frame()
  
  # Check if results or matches exist and is not empty
  if (!is.null(json_data$results) && "matches" %in% names(json_data$results)) {
    # Get matches data
    matches <- json_data$results$matches
    
    for (i in seq_along(matches)) {
      p_id <- json_data$results$xref[[i]]$id
      
      # Error handling
      if (length(p_id) > 1) {
        p_id <- p_id[1]
      }
      
      # Filter out entries where the entry type is "FAMILY"
      filtered_matches <- matches[[i]][matches[[i]]$`signature.entry.type` == "FAMILY", ]
      
      if (!("signature.entry.type" %in% names(matches))) {
        print(p_id)
      }
      
      filtered_matches <- filtered_matches %>% 
        dplyr::filter(`signature.entry.type` == "FAMILY")
      
      # If filtered_matches is not empty, process it
      if (nrow(filtered_matches) > 0) {
        
        # DEBUG
        if (length(filtered_matches$signature.entry.description) == 0) {
          print(p_id)
          if (filtered_matches$signature.entry.description == "Tripartite motif-containing") {
            print(filtered_matches)
          }
        }
        
        # Extract the necessary information
        entry_info <- filtered_matches %>%
          dplyr::mutate(Protein_accession = p_id) %>% 
          dplyr::select(
            Protein_accession,
            IPR_Accession = `signature.entry.accession`,
            Name = `signature.entry.name`,
            Description = `signature.entry.description`,
            Type = `signature.entry.type`
          )
        # Append this entry to the main data frame
        family_entries_df <- bind_rows(family_entries_df, entry_info)
      }  
    }
  }
  
  return(family_entries_df)
}
```

## Session Info

```{r}
sessionInfo()
```
